{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-F-422 -  Statistical Foundations of Machine Learning \n",
    "\n",
    "### Gian Marco Paldino - __[gian.marco.paldino@ulb.be](mailto:gian.marco.paldino@ulb.be)__\n",
    "### Cédric Simar - __[cedric.simar@ulb.be](mailto:cedric.simar@ulb.be)__\n",
    "\n",
    "## TP 5 - Ensembles of models and feature selection\n",
    "\n",
    "####  April 20, 2021\n",
    "\n",
    "#### Materials originally developed by *Yann-Aël Le Borgne, Fabrizio Carcillo and Gianluca Bontempi*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Feature selection and ensembles of models are two techniques which can be used to improve the accuracy of preditions. \n",
    "\n",
    "Feature selection aims at reducing the dimensionality of the problem, and is useful when input variables contain redundant or irrelevant (noisy) information. Benefits are twofold: it decreases the training time by simplifying the problem, and it decreases the complexity of the predictive model. This in turn usually improves the prediction accuracy, since high-dimensionality makes predictive models more prone to overfitting, and estimates of parameters more variant. \n",
    "\n",
    "There are three main approaches to feature selection:\n",
    "- **Filter methods:** \n",
    "These methods relies solely on the data and their intrinsic properties, without considering the impact of the selected features on the learning algorithm performance. For this reason, they are often used as preprocessing techniques.\n",
    "- **Wrapper methods:** \n",
    "These methods assess subsets of variables according to their usefulness to a given predictor. The feature selection is perfomed using an evaluation function that includes the predictive performance of the consider learning algorithm as a selection criterion. \n",
    "- **Embedded methods:** \n",
    "These methods are specific to given learning machines, and usually built-in in the learning procedure (e.g. random forest, regularization based techniques).\n",
    "\n",
    "Ensembles of models consist in building several predictive models using resampled subsets of the original training set. The method works particularly well for predictive models with high variance (for example, decision trees or neural networks). The average prediction of the resulting models usually strongly decreases the variance component of the error, and as a consequence improves the prediction accuracy. \n",
    "\n",
    "In this session, we will illustrate both techniques using the IMDB 5000 dataset, which contains 27 variables describing 5043 movies. The variables contain information about the director, actors, number of Facebook likes for each actor, duration, genre, language, country, etc... We will use them to predict the movie success (through the IMDB score). The dataset together with a description of the variables is at https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset.\n",
    "\n",
    "The dataset is on the github of the course, in `5_EnsemblesFeatureSelection/movie_metadata.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "The process of supervised learning involves the presence of an entity (the learner, also called prediction model), whose goal is to learn the mapping between inputs and outputs in a given problem.\n",
    "\n",
    "A supervised learning problem can formulated as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    " y = m(\\mathbf{x})  \n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    "- $y$ represents the output variable (also called target)\n",
    "- $\\mathbf{x}$ represents the vector of inputs (also called features).\n",
    "- $m$ is the (unknown) mapping between input and outputs.\n",
    "\n",
    "In the majority of the supervised learning problems, the mapping $m$ between input and outputs is unknown and needs to be estimated on basis of the available input/output observation pairs $(\\mathbf{x}_i,y_i)$.\n",
    "\n",
    "## Classification vs regression\n",
    "\n",
    "Both classification and regression are sub-fields of *supervised learning*. In the two cases, we have predictive variables $\\mathbf{x}$ and a target variable $y$. \n",
    "The main difference betweet the two type of problems is the type of the target variabile:\n",
    "\n",
    "- In classification, $y$ is a discrete variable; i.e $y \\in \\{C_1,\\cdots,C_k\\}$\n",
    "- In regression, $y$ is a continuous variable; i.e $y \\in \\mathbb{R}$\n",
    "\n",
    "In this practical, unlike the previous ones, we will tackle our problem as a regression problem, with the IMDB score being the continuous target variable to predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load and select a random subset of 1000 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data<-read.csv(\"movie_metadata.csv\",stringsAsFactors = T)\n",
    "set.seed(2)\n",
    "data<-data[sample(nrow(data),1000),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1000</li><li>28</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 28\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 28\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 28</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>color</th><th scope=col>director_name</th><th scope=col>num_critic_for_reviews</th><th scope=col>duration</th><th scope=col>director_facebook_likes</th><th scope=col>actor_3_facebook_likes</th><th scope=col>actor_2_name</th><th scope=col>actor_1_facebook_likes</th><th scope=col>gross</th><th scope=col>genres</th><th scope=col>actor_1_name</th><th scope=col>movie_title</th><th scope=col>num_voted_users</th><th scope=col>cast_total_facebook_likes</th><th scope=col>actor_3_name</th><th scope=col>facenumber_in_poster</th><th scope=col>plot_keywords</th><th scope=col>movie_imdb_link</th><th scope=col>num_user_for_reviews</th><th scope=col>language</th><th scope=col>country</th><th scope=col>content_rating</th><th scope=col>budget</th><th scope=col>title_year</th><th scope=col>actor_2_facebook_likes</th><th scope=col>imdb_score</th><th scope=col>aspect_ratio</th><th scope=col>movie_facebook_likes</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3925</th><td>Color</td><td>Oliver Stone</td><td>40</td><td>110</td><td>0</td><td>237</td><td>Zach Grenier</td><td>721</td><td>3468572</td><td>Drama          </td><td>Michael Wincott</td><td>Talk RadioÂ     </td><td>10073</td><td>1966</td><td>Bill Johnson </td><td>0</td><td>listener|neo nazi|radio|radio station|radio talk show</td><td>http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1</td><td>78</td><td>English</td><td>USA   </td><td>R</td><td>4e+06</td><td>1988</td><td>246</td><td>7.3</td><td>1.85</td><td>816</td></tr>\n",
       "\t<tr><th scope=row>4806</th><td>Color</td><td>Paul Fox    </td><td>80</td><td> 80</td><td>3</td><td> 39</td><td>Jeff Seymour</td><td>108</td><td>     NA</td><td>Horror|Thriller</td><td>Dov Tiefenbach </td><td>The Dark HoursÂ </td><td> 4788</td><td> 272</td><td>Gordon Currie</td><td>0</td><td>brain tumor|champagne|game|psychiatrist|weekend      </td><td>http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1</td><td>52</td><td>English</td><td>Canada</td><td>R</td><td>5e+05</td><td>2005</td><td> 64</td><td>6.1</td><td>1.85</td><td>166</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 28\n",
       "\\begin{tabular}{r|llllllllllllllllllllllllllll}\n",
       "  & color & director\\_name & num\\_critic\\_for\\_reviews & duration & director\\_facebook\\_likes & actor\\_3\\_facebook\\_likes & actor\\_2\\_name & actor\\_1\\_facebook\\_likes & gross & genres & actor\\_1\\_name & movie\\_title & num\\_voted\\_users & cast\\_total\\_facebook\\_likes & actor\\_3\\_name & facenumber\\_in\\_poster & plot\\_keywords & movie\\_imdb\\_link & num\\_user\\_for\\_reviews & language & country & content\\_rating & budget & title\\_year & actor\\_2\\_facebook\\_likes & imdb\\_score & aspect\\_ratio & movie\\_facebook\\_likes\\\\\n",
       "  & <fct> & <fct> & <int> & <int> & <int> & <int> & <fct> & <int> & <int> & <fct> & <fct> & <fct> & <int> & <int> & <fct> & <int> & <fct> & <fct> & <int> & <fct> & <fct> & <fct> & <dbl> & <int> & <int> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t3925 & Color & Oliver Stone & 40 & 110 & 0 & 237 & Zach Grenier & 721 & 3468572 & Drama           & Michael Wincott & Talk RadioÂ      & 10073 & 1966 & Bill Johnson  & 0 & listener\\textbar{}neo nazi\\textbar{}radio\\textbar{}radio station\\textbar{}radio talk show & http://www.imdb.com/title/tt0096219/?ref\\_=fn\\_tt\\_tt\\_1 & 78 & English & USA    & R & 4e+06 & 1988 & 246 & 7.3 & 1.85 & 816\\\\\n",
       "\t4806 & Color & Paul Fox     & 80 &  80 & 3 &  39 & Jeff Seymour & 108 &      NA & Horror\\textbar{}Thriller & Dov Tiefenbach  & The Dark HoursÂ  &  4788 &  272 & Gordon Currie & 0 & brain tumor\\textbar{}champagne\\textbar{}game\\textbar{}psychiatrist\\textbar{}weekend       & http://www.imdb.com/title/tt0402249/?ref\\_=fn\\_tt\\_tt\\_1 & 52 & English & Canada & R & 5e+05 & 2005 &  64 & 6.1 & 1.85 & 166\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 28\n",
       "\n",
       "| <!--/--> | color &lt;fct&gt; | director_name &lt;fct&gt; | num_critic_for_reviews &lt;int&gt; | duration &lt;int&gt; | director_facebook_likes &lt;int&gt; | actor_3_facebook_likes &lt;int&gt; | actor_2_name &lt;fct&gt; | actor_1_facebook_likes &lt;int&gt; | gross &lt;int&gt; | genres &lt;fct&gt; | actor_1_name &lt;fct&gt; | movie_title &lt;fct&gt; | num_voted_users &lt;int&gt; | cast_total_facebook_likes &lt;int&gt; | actor_3_name &lt;fct&gt; | facenumber_in_poster &lt;int&gt; | plot_keywords &lt;fct&gt; | movie_imdb_link &lt;fct&gt; | num_user_for_reviews &lt;int&gt; | language &lt;fct&gt; | country &lt;fct&gt; | content_rating &lt;fct&gt; | budget &lt;dbl&gt; | title_year &lt;int&gt; | actor_2_facebook_likes &lt;int&gt; | imdb_score &lt;dbl&gt; | aspect_ratio &lt;dbl&gt; | movie_facebook_likes &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 3925 | Color | Oliver Stone | 40 | 110 | 0 | 237 | Zach Grenier | 721 | 3468572 | Drama           | Michael Wincott | Talk RadioÂ      | 10073 | 1966 | Bill Johnson  | 0 | listener|neo nazi|radio|radio station|radio talk show | http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1 | 78 | English | USA    | R | 4e+06 | 1988 | 246 | 7.3 | 1.85 | 816 |\n",
       "| 4806 | Color | Paul Fox     | 80 |  80 | 3 |  39 | Jeff Seymour | 108 |      NA | Horror|Thriller | Dov Tiefenbach  | The Dark HoursÂ  |  4788 |  272 | Gordon Currie | 0 | brain tumor|champagne|game|psychiatrist|weekend       | http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1 | 52 | English | Canada | R | 5e+05 | 2005 |  64 | 6.1 | 1.85 | 166 |\n",
       "\n"
      ],
      "text/plain": [
       "     color director_name num_critic_for_reviews duration\n",
       "3925 Color Oliver Stone  40                     110     \n",
       "4806 Color Paul Fox      80                      80     \n",
       "     director_facebook_likes actor_3_facebook_likes actor_2_name\n",
       "3925 0                       237                    Zach Grenier\n",
       "4806 3                        39                    Jeff Seymour\n",
       "     actor_1_facebook_likes gross   genres          actor_1_name   \n",
       "3925 721                    3468572 Drama           Michael Wincott\n",
       "4806 108                         NA Horror|Thriller Dov Tiefenbach \n",
       "     movie_title      num_voted_users cast_total_facebook_likes actor_3_name \n",
       "3925 Talk RadioÂ      10073           1966                      Bill Johnson \n",
       "4806 The Dark HoursÂ   4788            272                      Gordon Currie\n",
       "     facenumber_in_poster plot_keywords                                        \n",
       "3925 0                    listener|neo nazi|radio|radio station|radio talk show\n",
       "4806 0                    brain tumor|champagne|game|psychiatrist|weekend      \n",
       "     movie_imdb_link                                      num_user_for_reviews\n",
       "3925 http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1 78                  \n",
       "4806 http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1 52                  \n",
       "     language country content_rating budget title_year actor_2_facebook_likes\n",
       "3925 English  USA     R              4e+06  1988       246                   \n",
       "4806 English  Canada  R              5e+05  2005        64                   \n",
       "     imdb_score aspect_ratio movie_facebook_likes\n",
       "3925 7.3        1.85         816                 \n",
       "4806 6.1        1.85         166                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.matrix.max.cols=50)\n",
    "data[1:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is a mix of categorical and numerical variables, and some missing values. In order to simplify the analysis, let us remove the categorical variables, and replace the NA values with the mean values of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>color</dt><dd>'factor'</dd><dt>director_name</dt><dd>'factor'</dd><dt>num_critic_for_reviews</dt><dd>'integer'</dd><dt>duration</dt><dd>'integer'</dd><dt>director_facebook_likes</dt><dd>'integer'</dd><dt>actor_3_facebook_likes</dt><dd>'integer'</dd><dt>actor_2_name</dt><dd>'factor'</dd><dt>actor_1_facebook_likes</dt><dd>'integer'</dd><dt>gross</dt><dd>'integer'</dd><dt>genres</dt><dd>'factor'</dd><dt>actor_1_name</dt><dd>'factor'</dd><dt>movie_title</dt><dd>'factor'</dd><dt>num_voted_users</dt><dd>'integer'</dd><dt>cast_total_facebook_likes</dt><dd>'integer'</dd><dt>actor_3_name</dt><dd>'factor'</dd><dt>facenumber_in_poster</dt><dd>'integer'</dd><dt>plot_keywords</dt><dd>'factor'</dd><dt>movie_imdb_link</dt><dd>'factor'</dd><dt>num_user_for_reviews</dt><dd>'integer'</dd><dt>language</dt><dd>'factor'</dd><dt>country</dt><dd>'factor'</dd><dt>content_rating</dt><dd>'factor'</dd><dt>budget</dt><dd>'numeric'</dd><dt>title_year</dt><dd>'integer'</dd><dt>actor_2_facebook_likes</dt><dd>'integer'</dd><dt>imdb_score</dt><dd>'numeric'</dd><dt>aspect_ratio</dt><dd>'numeric'</dd><dt>movie_facebook_likes</dt><dd>'integer'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[color] 'factor'\n",
       "\\item[director\\textbackslash{}\\_name] 'factor'\n",
       "\\item[num\\textbackslash{}\\_critic\\textbackslash{}\\_for\\textbackslash{}\\_reviews] 'integer'\n",
       "\\item[duration] 'integer'\n",
       "\\item[director\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_name] 'factor'\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[gross] 'integer'\n",
       "\\item[genres] 'factor'\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_name] 'factor'\n",
       "\\item[movie\\textbackslash{}\\_title] 'factor'\n",
       "\\item[num\\textbackslash{}\\_voted\\textbackslash{}\\_users] 'integer'\n",
       "\\item[cast\\textbackslash{}\\_total\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_name] 'factor'\n",
       "\\item[facenumber\\textbackslash{}\\_in\\textbackslash{}\\_poster] 'integer'\n",
       "\\item[plot\\textbackslash{}\\_keywords] 'factor'\n",
       "\\item[movie\\textbackslash{}\\_imdb\\textbackslash{}\\_link] 'factor'\n",
       "\\item[num\\textbackslash{}\\_user\\textbackslash{}\\_for\\textbackslash{}\\_reviews] 'integer'\n",
       "\\item[language] 'factor'\n",
       "\\item[country] 'factor'\n",
       "\\item[content\\textbackslash{}\\_rating] 'factor'\n",
       "\\item[budget] 'numeric'\n",
       "\\item[title\\textbackslash{}\\_year] 'integer'\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[imdb\\textbackslash{}\\_score] 'numeric'\n",
       "\\item[aspect\\textbackslash{}\\_ratio] 'numeric'\n",
       "\\item[movie\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "color\n",
       ":   'factor'director_name\n",
       ":   'factor'num_critic_for_reviews\n",
       ":   'integer'duration\n",
       ":   'integer'director_facebook_likes\n",
       ":   'integer'actor_3_facebook_likes\n",
       ":   'integer'actor_2_name\n",
       ":   'factor'actor_1_facebook_likes\n",
       ":   'integer'gross\n",
       ":   'integer'genres\n",
       ":   'factor'actor_1_name\n",
       ":   'factor'movie_title\n",
       ":   'factor'num_voted_users\n",
       ":   'integer'cast_total_facebook_likes\n",
       ":   'integer'actor_3_name\n",
       ":   'factor'facenumber_in_poster\n",
       ":   'integer'plot_keywords\n",
       ":   'factor'movie_imdb_link\n",
       ":   'factor'num_user_for_reviews\n",
       ":   'integer'language\n",
       ":   'factor'country\n",
       ":   'factor'content_rating\n",
       ":   'factor'budget\n",
       ":   'numeric'title_year\n",
       ":   'integer'actor_2_facebook_likes\n",
       ":   'integer'imdb_score\n",
       ":   'numeric'aspect_ratio\n",
       ":   'numeric'movie_facebook_likes\n",
       ":   'integer'\n",
       "\n"
      ],
      "text/plain": [
       "                    color             director_name    num_critic_for_reviews \n",
       "                 \"factor\"                  \"factor\"                 \"integer\" \n",
       "                 duration   director_facebook_likes    actor_3_facebook_likes \n",
       "                \"integer\"                 \"integer\"                 \"integer\" \n",
       "             actor_2_name    actor_1_facebook_likes                     gross \n",
       "                 \"factor\"                 \"integer\"                 \"integer\" \n",
       "                   genres              actor_1_name               movie_title \n",
       "                 \"factor\"                  \"factor\"                  \"factor\" \n",
       "          num_voted_users cast_total_facebook_likes              actor_3_name \n",
       "                \"integer\"                 \"integer\"                  \"factor\" \n",
       "     facenumber_in_poster             plot_keywords           movie_imdb_link \n",
       "                \"integer\"                  \"factor\"                  \"factor\" \n",
       "     num_user_for_reviews                  language                   country \n",
       "                \"integer\"                  \"factor\"                  \"factor\" \n",
       "           content_rating                    budget                title_year \n",
       "                 \"factor\"                 \"numeric\"                 \"integer\" \n",
       "   actor_2_facebook_likes                imdb_score              aspect_ratio \n",
       "                \"integer\"                 \"numeric\"                 \"numeric\" \n",
       "     movie_facebook_likes \n",
       "                \"integer\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sapply(data[1,],class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of categorical (factor) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>color</dt><dd>1</dd><dt>director_name</dt><dd>2</dd><dt>actor_2_name</dt><dd>7</dd><dt>genres</dt><dd>10</dd><dt>actor_1_name</dt><dd>11</dd><dt>movie_title</dt><dd>12</dd><dt>actor_3_name</dt><dd>15</dd><dt>plot_keywords</dt><dd>17</dd><dt>movie_imdb_link</dt><dd>18</dd><dt>language</dt><dd>20</dd><dt>country</dt><dd>21</dd><dt>content_rating</dt><dd>22</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[color] 1\n",
       "\\item[director\\textbackslash{}\\_name] 2\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_name] 7\n",
       "\\item[genres] 10\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_name] 11\n",
       "\\item[movie\\textbackslash{}\\_title] 12\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_name] 15\n",
       "\\item[plot\\textbackslash{}\\_keywords] 17\n",
       "\\item[movie\\textbackslash{}\\_imdb\\textbackslash{}\\_link] 18\n",
       "\\item[language] 20\n",
       "\\item[country] 21\n",
       "\\item[content\\textbackslash{}\\_rating] 22\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "color\n",
       ":   1director_name\n",
       ":   2actor_2_name\n",
       ":   7genres\n",
       ":   10actor_1_name\n",
       ":   11movie_title\n",
       ":   12actor_3_name\n",
       ":   15plot_keywords\n",
       ":   17movie_imdb_link\n",
       ":   18language\n",
       ":   20country\n",
       ":   21content_rating\n",
       ":   22\n",
       "\n"
      ],
      "text/plain": [
       "          color   director_name    actor_2_name          genres    actor_1_name \n",
       "              1               2               7              10              11 \n",
       "    movie_title    actor_3_name   plot_keywords movie_imdb_link        language \n",
       "             12              15              17              18              20 \n",
       "        country  content_rating \n",
       "             21              22 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factor_variables<-which(sapply(data[1,],class)==\"factor\")\n",
    "factor_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " num_critic_for_reviews    duration   director_facebook_likes\n",
       " Min.   :  1.0          Min.   :  7   Min.   :    0.00       \n",
       " 1st Qu.: 48.0          1st Qu.: 93   1st Qu.:    6.75       \n",
       " Median :103.0          Median :103   Median :   44.00       \n",
       " Mean   :135.1          Mean   :106   Mean   :  669.26       \n",
       " 3rd Qu.:184.2          3rd Qu.:116   3rd Qu.:  204.75       \n",
       " Max.   :765.0          Max.   :511   Max.   :21000.00       \n",
       " NA's   :16             NA's   :4     NA's   :24             \n",
       " actor_3_facebook_likes actor_1_facebook_likes     gross          \n",
       " Min.   :    0.0        Min.   :    0          Min.   :      703  \n",
       " 1st Qu.:  120.0        1st Qu.:  623          1st Qu.:  5003486  \n",
       " Median :  395.0        Median :  979          Median : 25025352  \n",
       " Mean   :  602.2        Mean   : 5951          Mean   : 46927291  \n",
       " 3rd Qu.:  642.0        3rd Qu.:11000          3rd Qu.: 60549232  \n",
       " Max.   :19000.0        Max.   :49000          Max.   :658672302  \n",
       " NA's   :5              NA's   :3              NA's   :200        \n",
       " num_voted_users  cast_total_facebook_likes facenumber_in_poster\n",
       " Min.   :     5   Min.   :    0             Min.   : 0.000      \n",
       " 1st Qu.:  7110   1st Qu.: 1466             1st Qu.: 0.000      \n",
       " Median : 31625   Median : 3142             Median : 1.000      \n",
       " Mean   : 76398   Mean   : 9103             Mean   : 1.394      \n",
       " 3rd Qu.: 87767   3rd Qu.:13884             3rd Qu.: 2.000      \n",
       " Max.   :955174   Max.   :77823             Max.   :31.000      \n",
       "                                            NA's   :2           \n",
       " num_user_for_reviews     budget            title_year   actor_2_facebook_likes\n",
       " Min.   :   1.00      Min.   :     3250   Min.   :1916   Min.   :    0.0       \n",
       " 1st Qu.:  60.25      1st Qu.:  5000000   1st Qu.:1999   1st Qu.:  299.8       \n",
       " Median : 154.50      Median : 18013074   Median :2005   Median :  602.0       \n",
       " Mean   : 257.51      Mean   : 31645256   Mean   :2002   Mean   : 1720.3       \n",
       " 3rd Qu.: 316.00      3rd Qu.: 40000000   3rd Qu.:2011   3rd Qu.:  934.0       \n",
       " Max.   :3597.00      Max.   :260000000   Max.   :2016   Max.   :29000.0       \n",
       " NA's   :6            NA's   :104         NA's   :24     NA's   :4             \n",
       "   imdb_score     aspect_ratio    movie_facebook_likes\n",
       " Min.   :1.900   Min.   : 1.330   Min.   :     0      \n",
       " 1st Qu.:5.800   1st Qu.: 1.850   1st Qu.:     0      \n",
       " Median :6.500   Median : 2.350   Median :    65      \n",
       " Mean   :6.426   Mean   : 2.289   Mean   :  6947      \n",
       " 3rd Qu.:7.200   3rd Qu.: 2.350   3rd Qu.:  1000      \n",
       " Max.   :8.900   Max.   :16.000   Max.   :199000      \n",
       "                 NA's   :80                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_preprocessed<-data[,-factor_variables]\n",
    "summary(data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NA values with mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "replace_na_with_mean_value<-function(vec) {\n",
    "    mean_vec<-mean(vec,na.rm=T)\n",
    "    vec[is.na(vec)]<-mean_vec\n",
    "    vec\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " num_critic_for_reviews    duration   director_facebook_likes\n",
       " Min.   :  1.0          Min.   :  7   Min.   :    0.0        \n",
       " 1st Qu.: 48.0          1st Qu.: 93   1st Qu.:    7.0        \n",
       " Median :105.5          Median :103   Median :   48.5        \n",
       " Mean   :135.1          Mean   :106   Mean   :  669.3        \n",
       " 3rd Qu.:181.0          3rd Qu.:116   3rd Qu.:  234.0        \n",
       " Max.   :765.0          Max.   :511   Max.   :21000.0        \n",
       " actor_3_facebook_likes actor_1_facebook_likes     gross          \n",
       " Min.   :    0.0        Min.   :    0.0        Min.   :      703  \n",
       " 1st Qu.:  120.0        1st Qu.:  623.8        1st Qu.:  9158619  \n",
       " Median :  397.5        Median :  982.0        Median : 38108330  \n",
       " Mean   :  602.2        Mean   : 5950.9        Mean   : 46927291  \n",
       " 3rd Qu.:  642.0        3rd Qu.:11000.0        3rd Qu.: 47159944  \n",
       " Max.   :19000.0        Max.   :49000.0        Max.   :658672302  \n",
       " num_voted_users  cast_total_facebook_likes facenumber_in_poster\n",
       " Min.   :     5   Min.   :    0             Min.   : 0.000      \n",
       " 1st Qu.:  7110   1st Qu.: 1466             1st Qu.: 0.000      \n",
       " Median : 31625   Median : 3142             Median : 1.000      \n",
       " Mean   : 76398   Mean   : 9103             Mean   : 1.394      \n",
       " 3rd Qu.: 87767   3rd Qu.:13884             3rd Qu.: 2.000      \n",
       " Max.   :955174   Max.   :77823             Max.   :31.000      \n",
       " num_user_for_reviews     budget            title_year   actor_2_facebook_likes\n",
       " Min.   :   1.0       Min.   :     3250   Min.   :1916   Min.   :    0.0       \n",
       " 1st Qu.:  61.0       1st Qu.:  6500000   1st Qu.:1999   1st Qu.:  301.5       \n",
       " Median : 156.0       Median : 22000000   Median :2005   Median :  605.0       \n",
       " Mean   : 257.5       Mean   : 31645256   Mean   :2002   Mean   : 1720.3       \n",
       " 3rd Qu.: 315.2       3rd Qu.: 37000000   3rd Qu.:2010   3rd Qu.:  936.5       \n",
       " Max.   :3597.0       Max.   :260000000   Max.   :2016   Max.   :29000.0       \n",
       "   imdb_score     aspect_ratio    movie_facebook_likes\n",
       " Min.   :1.900   Min.   : 1.330   Min.   :     0      \n",
       " 1st Qu.:5.800   1st Qu.: 1.850   1st Qu.:     0      \n",
       " Median :6.500   Median : 2.289   Median :    65      \n",
       " Mean   :6.426   Mean   : 2.289   Mean   :  6947      \n",
       " 3rd Qu.:7.200   3rd Qu.: 2.350   3rd Qu.:  1000      \n",
       " Max.   :8.900   Max.   :16.000   Max.   :199000      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_preprocessed<-data.frame(apply(data_preprocessed,2,replace_na_with_mean_value))\n",
    "summary(data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable (Y) is the `imdb_score`, and all other variables (X) are considered as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "\n",
    "X<-data_preprocessed[,setdiff(colnames(data_preprocessed),\"imdb_score\")]\n",
    "Y<-data_preprocessed[,\"imdb_score\"]\n",
    "\n",
    "N<-nrow(X)    #Number of examples\n",
    "n<-ncol(X)    #Number of input variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the `imdb_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Histogram of Y\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "6.4255"
      ],
      "text/latex": [
       "6.4255"
      ],
      "text/markdown": [
       "6.4255"
      ],
      "text/plain": [
       "[1] 6.4255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.2469466966967"
      ],
      "text/latex": [
       "1.2469466966967"
      ],
      "text/markdown": [
       "1.2469466966967"
      ],
      "text/plain": [
       "[1] 1.246947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Modelling with linear and decision tree models\n",
    "\n",
    "#### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us create a linear model for predicting the IMDB score on the basis of the other variables, and compute its empricial mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DS<-cbind(X,imdb_score=Y)\n",
    "    \n",
    "model<- ### Fill with your code here\n",
    "        \n",
    "Y.hat<- predict(model,X)\n",
    "        \n",
    "empirical_error<- ### Fill with your code here\n",
    "\n",
    "print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which input variables are statistically correlated with the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the validation error with a 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-  ### Complete the code. i.ts should be the indices of the test for the i-th fold\n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     i.tr<-  ### Complete the code. i.tr should be the indices of the training sefor the i-th fold\n",
    "     X.tr<-X[i.tr,]\n",
    "     Y.tr<-Y[i.tr]                          \n",
    "     \n",
    "     DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "     model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "     Y.hat.ts<- predict(model,X.ts)\n",
    "        \n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "}\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify the previous code to compute the empirical error using a decision tree model. Use the rpart package (see `?rpart` for help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(rpart)       ### Run install.packages(\"rpart\") to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DS<-cbind(X,imdb_score=Y)\n",
    "\n",
    "model<- ### Fill with you code here\n",
    "        \n",
    "Y.hat<- predict(model,X)\n",
    "        \n",
    "empirical_error<-mean((Y.hat-Y)^2) \n",
    "\n",
    "print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the resulting tree using the `prp` function from the library `rpart.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(rpart.plot)  ### Run install.packages(\"rpart.plot\") to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "prp(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the 10-fold cross-validation error using a decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     i.tr<-setdiff(1:N,i.ts)                \n",
    "     X.tr<-X[i.tr,]\n",
    "     Y.tr<-Y[i.tr]                          \n",
    "     \n",
    "     DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "     model<- rpart(imdb_score~.,DS)\n",
    "        \n",
    "     Y.hat.ts<- predict(model,X.ts)\n",
    "        \n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create an ensemble of $R$ linear models to make predictions. Complete the code below so that:\n",
    "\n",
    "* The training set is resampled before building a model\n",
    "* The predictions of all model are averaged before testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "R<-20\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     \n",
    "     i.tr<-setdiff(1:N,i.ts)                \n",
    "    \n",
    "     Y.hat.ts.R<-matrix(0,nrow=nrow(X.ts),ncol=R)\n",
    "    \n",
    "     for (r in 1:R) {\n",
    "         i.tr.resample<-    ### Complete code: Resample training set with replacement\n",
    "         X.tr<-X[i.tr.resample,]\n",
    "         Y.tr<-Y[i.tr.resample]                          \n",
    "     \n",
    "         DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "         model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "         Y.hat.ts.R[,r]<- predict(model,X.ts)\n",
    "     \n",
    "     }\n",
    "    \n",
    "     Y.hat.ts<-apply(Y.hat.ts.R,1,mean)\n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "     }\n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the CV error lower than with a single linear model?\n",
    "* Use a decision tree as the base model. Is the CV error lower?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature selection\n",
    "\n",
    "Two are the main approaches to feature selection:\n",
    "\n",
    "\n",
    "* **Filter methods:** they are preprocessing methods. They attempt to\n",
    "assess the merits of features from the data, ignoring the effects of\n",
    "the selected feature subset on the performance of the learning\n",
    "algorithm. Examples are methods that select variables by ranking them\n",
    "through compression techniques (like PCA), or by computing correlation or a more advanced similarity measure such as minimum redundancy maximum relevance (mRMR) with the output.\n",
    "\n",
    "*  **Wrapper methods:** these methods assess subsets of variables\n",
    "according to their usefulness to a given predictor. The method\n",
    "conducts a search for a good subset using the learning algorithm\n",
    "itself as part of the evaluation function. The problem boils \n",
    "down to a problem of stochastic state space search. Example\n",
    "are the stepwise methods proposed in linear regression analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with the output\n",
    "\n",
    "* The following code performs features selection by keeping the most correlated variables with the output. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "     \n",
    "    correlation<-abs(cor(X.tr,Y.tr))\n",
    "    ranking<-sort(correlation,dec=T,index.return=T)$ix\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,ranking[1:nb_features],drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,ranking[1:nb_features],drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mRMR\n",
    "\n",
    "* The following code performs features selection by using the mRMR approach (see Section 12.8 - Syllabus). Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "    \n",
    "    \n",
    "    correlation<-abs(cor(X.tr,Y.tr))\n",
    "    \n",
    "    selected<-c()\n",
    "    candidates<-1:n\n",
    "    \n",
    "    #mRMR ranks the variables by taking account not only the correlation with the output, but also by avoiding redudant variables\n",
    "    for (j in 1:n) {\n",
    "        redudancy.score<-numeric(length(candidates))\n",
    "        if (length(selected)>0) {\n",
    "            cor.selected.candidates<-cor(X.tr[,selected,drop=F],X.tr[,candidates,drop=F])\n",
    "            redudancy.score<-apply(cor.selected.candidates,2,mean)\n",
    "        }\n",
    "        \n",
    "        mRMR.score<-correlation[candidates]-redudancy.score\n",
    "        \n",
    "        selected_current<-candidates[which.max(mRMR.score)]\n",
    "        selected<-c(selected,selected_current)\n",
    "        candidates<-setdiff(candidates,selected_current)\n",
    "    }\n",
    "    \n",
    "    ranking<-selected\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,ranking[1:nb_features],drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,ranking[1:nb_features],drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "* The following code performs features selection by first transforming the inputs using PCA, and then keeping the most relevant principal components in the model. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "X_pca<-data.frame(prcomp(X,retx=T)$x)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X_pca[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X_pca[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,1:nb_features,drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,1:nb_features,drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper method: Forward selection\n",
    "\n",
    "* The following code performs features selection by using a forward selection method (Section 12.4 - Syllabus). Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "selected<-NULL\n",
    "\n",
    "for (round in 1:n) { \n",
    "    candidates<-setdiff(1:n,selected)\n",
    "    \n",
    "    CV.err<-matrix(0,nrow=length(candidates),ncol=10)\n",
    "    \n",
    "    for (j in 1:length(candidates)) {\n",
    "        features_to_include<-c(selected,candidates[j])\n",
    "        \n",
    "        for (i in 1:10) {\n",
    "            i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "            X.ts<-X[i.ts,features_to_include,drop=F]  \n",
    "            Y.ts<-Y[i.ts]  \n",
    "     \n",
    "            i.tr<-setdiff(1:N,i.ts)\n",
    "            X.tr<-X[i.tr,features_to_include,drop=F]\n",
    "            Y.tr<-Y[i.tr]\n",
    "     \n",
    "            DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "            model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "            Y.hat.ts<- predict(model,X.ts)\n",
    "        \n",
    "            CV.err[j,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "        }\n",
    "    }\n",
    "    CV.err.mean<-apply(CV.err,1,mean)\n",
    "    CV.err.sd<-apply(CV.err,1,sd)\n",
    "    selected_current<-which.min(CV.err.mean)              \n",
    "    selected<-c(selected,candidates[selected_current])\n",
    "    print(paste(\"Round \",round,\" ; Selected feature: \",candidates[selected_current],\" ; CV error=\",round(CV.err.mean[selected_current],digits=4), \" ; std dev=\",round(CV.err.sd[selected_current],digits=4)))\n",
    "\n",
    "}\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further preprocessing to add categorical variables\n",
    "\n",
    "Categorical variables usually need to be transformed with 'one-hot-encoding' in order to be processed by a learning algorithm. That is, for each value of the categorical variable, a binary feature is created, which is set to one whenever that value is present. This can be done using the `dummy.data.frame` of the `dummies` package.\n",
    "\n",
    "```\n",
    "install.packages('dummies')\n",
    "library(dummies)\n",
    "```\n",
    "\n",
    "In the following, we add some categorical variables to the peprocessing dataset. The set of categorical variables is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "factor_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have an overview of the their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_factor<-data[,factor_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dim(data_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_factor[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us keep four of them: Color, language, country and content_rating, and transform them with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "variable_to_keep<-c(\"color\",\"language\",\"country\",\"content_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_factor_onehot <- dummy.data.frame(data_factor[,variable_to_keep], sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dim(data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_factor_onehot[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These could be added to the previously preprocessed dataset, and used to further improve the prediction accuracy using the feature selection/ensemble techniques seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed_extended<-cbind(data_preprocessed,data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dim(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other predictive models\n",
    "\n",
    "Other models could be used, for example support vector machines, neural networks, K-nearest neighbors (using the `svm`, `nnt`or `lazy` functions from the `e1071`, `nnet` or `lazy` packages, respectively). Note that scaling the data is usually necessary when using neural networks and K-nearest neighbors approaches. \n",
    "Is the usage of different models improving the predictive performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
